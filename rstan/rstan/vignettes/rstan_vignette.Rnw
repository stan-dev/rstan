\documentclass[12pt]{article}
\usepackage{Sweave}
\usepackage{hyperref}
\usepackage{times}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{xspace}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{url}
\usepackage{booktabs} 
\usepackage{enumerate}
\usepackage{alltt}
\usepackage{multirow}
\usepackage{makeidx}
\usepackage{verbatimbox}


\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=2em,fontsize=\footnotesize} 
\DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=2em,fontsize=\footnotesize} 
\DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=2em,fontsize=\footnotesize}

\newcommand{\R}{R\xspace}
\newcommand{\Stan}{Stan\xspace}
\newcommand{\CmdStan}{CmdStan\xspace}
\newcommand{\RStan}{RStan\xspace}
\newcommand{\stanc}{{\ttfamily stanc}\xspace}
\newcommand*{\Cpp}{C\raise.2ex\hbox{\footnotesize ++}\xspace} %\ensuremath{++}
\newcommand{\clang}{{\ttfamily clang\raise.2ex\hbox{\footnotesize ++}}\xspace} 
\newcommand{\gpp}{{\ttfamily g\raise.2ex\hbox{\footnotesize ++}}\xspace} 
\newcommand{\clangpp}{{\ttfamily clang\raise.2ex\hbox{\footnotesize ++}}\xspace} 

\providecommand{\T}{\rule{0pt}{2.6ex}}
\providecommand{\B}{\rule[-1.2ex]{0pt}{0pt}}

\providecommand{\rstanfunidx}[1]{\index{\pkg{rstan} functions!#1}}

\newcommand{\acronym}[1]{{\sc #1}\xspace}

\newcommand{\ASCII}{\acronym{ascii}}
\newcommand{\BNF}{\acronym{bnf}}
\newcommand{\MATLAB}{\acronym{matlab}}
\newcommand{\SPLUS}{\acronym{s}}
\newcommand{\BUGS}{\acronym{bugs}}
\newcommand{\JAGS}{\acronym{jags}}
\newcommand{\MCMC}{\acronym{mcmc}}
\newcommand{\HMC}{\acronym{hmc}}
\newcommand{\NUTS}{\acronym{nuts}}
\newcommand{\MSVC}{\acronym{msvc}}
\newcommand{\LKJ}{\acronym{lkj}}
\newcommand{\CPC}{\acronym{cpc}}

\newcommand{\code}[1]{{\tt #1}}

\newcommand{\strong}[1]{\texorpdfstring%
{{\normalfont\fontseries{b}\selectfont #1}}%
{#1}}
\let\pkg=\strong
\newcommand{\CRANpkg}[1]{\href{http://cran.r-project.org/package=#1}{\pkg{#1}}}%
\let\cpkg=\CRANpkg
\newcommand{\ctv}[1]{\href{http://CRAN.R-project.org/view=#1}{\emph{#1}}}
\newenvironment{example}{\begin{alltt}}{\end{alltt}}
\newenvironment{smallexample}{\begin{alltt}\small}{\end{alltt}}

\newcommand{\E}{\mathsf{E}}
\newcommand{\VAR}{\mathsf{VAR}}
\newcommand{\COV}{\mathsf{COV}}
\newcommand{\Prob}{\mathsf{P}}

\bibliographystyle{apalike}

%\VignetteIndexEntry{RStan} 

% The next line is needed for inverse search...
\SweaveOpts{concordance=TRUE, keep.source=TRUE, cache=TRUE}
<<echo=false>>=
options(width=80)
library(rstan)
@

\title{\RStan: the \R interface to \Stan} 

\author{The Stan Development Team \\ stan@mc-stan.org}
\makeindex

\begin{document}

\maketitle

\tableofcontents

\begin{abstract}
In this vignette we present the \RStan package \pkg{rstan} for using Stan in \R. 
\Stan is a package for making Bayesian inferences using the No-U-Turn sampler (a 
variant of Hamiltonian Monte Carlo) or frequentist inference via optimization. We 
illustrate the features of \RStan through an example in \cite{GelmanCarlinSternRubin:2003}.
\end{abstract}


\section{Introduction}

\Stan is a \Cpp program for Bayesian modeling and inference
that uses the No-U-Turn sampler (NUTS) (\citealt{hoffman-gelman:2012})
to obtain posterior simulation given user-specified model and data. Alternatively,
\Stan can utilize the LBFGS optimization algorithm to maximize an objective function,
such as a log-likelihood. The \R package, \pkg{rstan} allows one to conveniently 
use \Stan from \R (\citealt{rprj}) and to access \Stan output, which includes
posterior inferences and also intermediate quantities such as evaluation
of the log posterior density and its gradients. 

The website for \Stan and \RStan, \url{http://mc-stan.org},
provides up-to-date information about how to operate \Stan and \RStan.
For example, ``\RStan Getting Started'' (\citealt{rstangettingstarted2012})
has a couple of examples.  The present article provides 
a complete introduction to the functionality of package \pkg{rstan} and
provides pointers to many functions in \pkg{rstan} from the user's perspective.

We start with the prerequisites for using \pkg{rstan} 
(section \ref{subsec0pre}) and a typical workflow of using \Stan
and \RStan (section \ref{subsec0workflow}). 
In section \ref{sec0example}, we  illustrate the process 
of using \pkg{rstan} to estimate a Bayesian model.
Section \ref{sec0moredetails} presents further details on \pkg{rstan}. 
In section \ref{sec0workwstan}, we discuss some functions that \pkg{rstan}
provides to access the results when \Stan is used from the command line. 

\subsection{Prerequisites} 
\label{subsec0pre}

Users need to know how to specify statistical models 
using the \Stan modeling language, which is detailed 
in the manual of \Stan (\citealt{StanManual}).
We give an example below. To do so, a \Cpp compiler is required, such as
\gpp\footnote{\url{http://gcc.gnu.org}} or \clangpp\footnote{\url{http://clang.llvm.org}}.
There are instructions on how to install a \Cpp compiler at \url{http://mc-stan.org}.

Package \pkg{rstan} depends on several other \R packages: 
\begin{itemize}
 \item \cpkg{StanHeaders} which provides the \Stan \Cpp headers
 \item \cpkg{BH} which provides Boost \Cpp headers
 \item \cpkg{RcppEigen} which provides Eigen \Cpp headers
 \item \cpkg{Rcpp} which facilitates using \Cpp from \R
 \item \cpkg{inline} which compiles \Cpp for use with \R
\end{itemize}

\subsection[Typical workflow of using RStan]{Typical workflow of using RStan}
\label{subsec0workflow}

\Stan has a modeling language, which is similar to 
but not identical to that of the Bayesian graphical modeling package 
BUGS (\citealt{WinBUGS}). A parser translates the model expressed in the \Stan modeling 
language to \Cpp code, whereupon it is compiled to an executable program and loaded as
a Dynamic Shared Object (DSO) in the \R global environment and can be called by the user.
In summary, the following are typical steps of using \Stan for Bayesian inference. 
\begin{enumerate}[a.]\addtolength{\itemsep}{-0.6\baselineskip}
\item Represent a statistical model by writing its log posterior
      density (up to an arbitrary normalizing constant that does not 
      depends on the unknown parameters in the model) using \Stan modeling language. 
\item Translate the model coded in \Stan modeling language to \Cpp code using the \stanc
      function
\item Compile the \Cpp code for the model using a \Cpp compiler to
      create a DSO (also called a dynamic link library (DLL)) that can be loaded by \R.
\item Run the DSO to sample from the posterior distribution using the \code{stan} or 
      \code{sampling} functions
\item Diagnose non-convergence of the MCMC chains
\item Conduct inference based on the samples from the posterior distribution
\end{enumerate}

Steps c, d, and e above are all performed implicitly by a single \code{stan} call.

\section[An example of using rstan]{An example of using \pkg{rstan}}
\label{sec0example} 

In section 5.5 of \cite{GelmanCarlinSternRubin:2003}, a hierarchical model is
used to model the effect of coaching programs on college admissions 
tests.  The data, shown in Table~\ref{tab08schoolsdata}, summarize the results
of experiments conducted in eight high schools, with an estimated standard 
error for each, and these data and model are of historical interest as an example
of full Bayesian inference (\citealt{Rubin1981}). 
We use this example here for its simplicity and because it represents a nontrivial
Markov chain simulation problem in that there is dependence between the parameters 
of original interest in the study --- the effects of coaching in each of the eight 
schools --- and the hyperparameter representing the variation of these effects in the 
modeled population.  Certain implementations of a Gibbs sampler or a Hamiltonian 
Monte Carlo sampler can be slow to converge in this example. 
For short, we call this example ``eight schools.'' 
The statistical model is specified as 
\begin{align}
y_j &\sim \text{normal}(\theta_j, \sigma_j^2), \quad j=1,\ldots,8 \\ 
\theta_1, \ldots, \theta_8 &\sim \text{normal}(\mu, \tau^2), 
\end{align} 
in which each $\sigma_j$'s assumed known and a uniform prior 
density is used, $p(\mu, \tau) \propto 1$. 

\begin{table}
\begin{center}\begin{tabular}{ccc}
&\multicolumn{1}{c}{Estimated}&\multicolumn{1}{c}{Standard error}\\
&\multicolumn{1}{c}{treatment}&\multicolumn{1}{c}{of effect}\\
School&\multicolumn{1}{c}{effect, $y_j$}&
\multicolumn{1}{c}{estimate, $\sigma_j$}\\\hline
A& \ 28 & 15 \\
B& \ \,\, 8 & 10 \\
C& $\,-3$ & 16 \\
D& \ \,\, 7 & 11 \\
E& $\,-1$ & \ 9 \\
F& \ \,\, 1 & 11 \\
G& \ 18 & 10 \\
H& \ 12 & 18
\end{tabular}
\end{center}
\caption{Observed effects of coaching on college admissions test scores in
eight schools.  We fit these data using a hierarchical model allowing variation
between schools.}
\label{tab08schoolsdata}
\end{table}

\subsection{Express the model in Stan}

We first need to express this model in the \Stan modeling language. The \pkg{rstan} 
package allows a model to be coded in a text file (typically with suffix \code{.stan}) 
or in a \R character vector (perhaps of length one). 
We put the following text into a file called schools.stan: 
\begin{Schunk}
\begin{Sinput}
data {
  int<lower=0> J; // number of schools 
  real y[J];      // estimated treatment effects
  real<lower=0> sigma[J]; // s.e. of effect estimates 
}
parameters {
  real mu; 
  real<lower=0> tau;
  vector[J] eta;
}
transformed parameters {
  vector[J] theta;
  theta <- mu + tau * eta;
}
model {
  eta ~ normal(0, 1);
  y ~ normal(theta, sigma);
}
\end{Sinput}
\end{Schunk}

The first section of the above code specifies the data that is conditioned upon by
Bayes Rule:  the number of schools, $J$; the vector of estimates, $y_1,\dots,y_J$; and 
the standard errors, $\sigma_{1},\dots\sigma_{J}$.  Data are labeled as integer or real and
can be vectors (or, more generally, arrays) if dimensions are specified.  Data
can also be constrained; for example, in the above model $J$ has been
restricted to be nonnegative and the components of $\sigma_y$ must all be positive.

The next section of the code defines the parameters whose posterior distribution is sought
using Bayes Rule. These are the their mean, $\mu$, and standard deviation, $\tau$, of the 
school effects, plus the standardized school-level effects $\eta$. In this model, we let
the undstandardized school-level effects, $\theta$, be a transformed parameter that uses
$\mu$ and $\tau$ to shift and scale the standardized effects $\eta$ instead of
directly declaring $\theta$ as a parameter. By parameterizing the model this way, the
sampler runs more efficiently because the resulting multivariate geometry is more amendable
to Hamiltonian Monte Carlo (\citealt{Neal:2011}).

Finally, the model block looks similar to standard statistical notation.
(Just be careful:  the second argument to Stan's normal$(\cdot,\cdot)$
distribution is the standard deviation, not the variance as is usual in
statistical notation.)  We have written the model in vector notation, which
allows Stan to make use of more efficient algorithmic differentiation (AD).  It
would also be possible --- but less efficient --- to write the model by
replacing \verb+y ~ normal(theta,sigma);+ with a loop over the $J$ schools,
\verb+for (j in 1:J) y[j] ~ normal(theta[j],sigma[j]);+\,.

\Stan has versions of many of the most useful \R functions for statistical modeling, 
including probability distributions, matrix operations, and special functions. However,
the names of the \Stan functions may differ from their \R counterparts and more subtly,
the parameterizations of probability distributions in \Stan may differ from those in \R
for the same distribution. To mitigate this problem, the \code{lookup} function can be
passed a \R function or character string naming an \R function, and \pkg{rstan} will 
attempt to look up the corresponding \Stan function, display its arguments, and give
the page number in \cite{StanManual} where the \Stan function is discussed.

<<lookup, echo=TRUE>>=
lookup("dnorm")
tail(lookup("~")) # looks up all Stan sampling statements
lookup(dwilcox)   # no corresponding Stan function
@

\subsection{User-defined Stan functions}

\Stan permits users to define their own functions in a functions block of a \Stan
program. The functions block is optional but if it exists, it must come before any
other block. This mechanism allows users to implement statistical distributions or
other functionality that is not currently available in \Stan. However, even if the
user's function merely wraps calls to existing \Stan functions, the code in the model
block can be much more readible if several lines of \Stan code that accomplish one
(or perhaps two) task(s) are replaced by a call to a user-defined function.

Another reason to utilize user-defined functions is that \pkg{rstan} provides a 
\code{testify} function that exports such functions to the \R global environment so
that they can be tested in \R to ensure that they are working properly. For example,

<<testify, echo=TRUE>>=
model_code <-
'
functions {
  real standard_normal_rng() {
    return normal_rng(0,1);
  }
}
model {}
'
testify(stanc(model_code = model_code))
standard_normal_rng(seed = 1)
@


\subsection{Preparing the data}

The \code{stan} function in \pkg{rstan} accepts data as a \code{list} or an \code{environment}. 
To prepare the data in \R, we create a \code{list} as follows. 
<<echo=TRUE>>=
schools_data <- 
  list(J=8, 
  y=c(28,  8, -3,  7, -1,  1, 18, 12),
  sigma=c(15, 10, 16, 11,  9, 11, 10, 18))
@

Often we would already have the elements of the data for a model
defined in our workspace. In \pkg{rstan}, a convenient way is to 
provide just the names instead of creating a new list. The following
\R code demonstrates this feature. 
<<echo=TRUE>>=
J <- 8
y <- c(28,  8, -3,  7, -1,  1, 18, 12)
sigma <- c(15, 10, 16, 11,  9, 11, 10, 18)
schools_data_nms <- c("J", "y", "sigma") 
@

It would also be possible (indeed, encouraged) to read in the data
from a file rather than to directly enter 
the numbers in the \R script. 

\subsection{Sample from the posterior distribution}
\label{subsec0stansampling}

Next, we can call the \code{stan} function to draw posterior samples:
<<callstan, echo=TRUE, results=hide, cache=TRUE>>=
fit1 <- stan(file="schools.stan", data=schools_data, 
             iter=2000, chains=4)
@

Function \code{stan} wraps the following three steps: 
\begin{enumerate}[a.]\addtolength{\itemsep}{-0.6\baselineskip}
\item Translate a model in \Stan code to \Cpp code 
\item Compile the \Cpp code to a dynamic shared object (DSO) and load the DSO
\item Sample given some user-specified data and other settings
\end{enumerate}

A single call to \code{stan} performs all three steps, but they can also be  
executed one by one, which can be useful for debugging.   In addition, \Stan
saves the DSO so that when the same model is fit again (possibly with new
data), function \code{stan} can be called so that only the third step is performed, thus
saving compile time.

Function \code{stan} returns an object of S4\footnote{For those who are not familiar 
with the concept of class and S4 class in \R, refer to \cite{chambers2010software}. 
A S4 class consists of some attributes (data) to model an object and 
some methods to model the behavior of the object. From a user's perspective,  
once a \code{stanfit} object is created, we are mainly concerned about what methods 
are defined for the \code{stanfit}.} class \code{stanfit}.
If no error occurs, the returned \code{stanfit} 
object includes the samples drawn from the posterior distribution for the 
model parameters and other quantities defined in the model. 
If there is an error (for example, when we have syntax error in our \Stan code),
\code{stan} will either quit or return a \code{stanfit} object that contains no
samples. Including the DSO as part of a \code{stanfit} object
allows it to be reused so that compiling the same model could be avoided when
we want to sample again with the same or different input of data and other settings.
Also if an error happens after the model is compiled but before sampling (for
example, problems with input such as data and initial values),
we can reuse the previous compiled model. 
For class \code{stanfit}, many methods such as \code{print} and \code{plot} 
are defined to work with the samples and conduct model inference. For example, 
the following shows a summary of the parameters for our
example using function \code{print}.
<<echo=TRUE>>=
print(fit1, pars=c("theta", "mu", "tau", "lp__"), 
      probs=c(.1,.5,.9))
@

The last line of this output, {\tt lp\_\_}, is the logarithm of the
(unnormalized) posterior density as calculated by \Stan.  This log density can be used 
in various ways for model evaluation and comparison (see, e.g., \citealt{Vehtari2012}).
%Vehtari, A., and Ojanen, J. (2012). A survey of Bayesian predictive methods
%for model assessment, selection and comparison. 
%Statistics Surveys 6, 142-228. 


\section[Advanced features]{Advanced features}
\label{sec0moredetails}

In this section, we discuss more details and other advanced 
features of \pkg{rstan}. The details pertain to the optional
arguments of the \code{stan} function, data preprocessing, and methods for the
S4 class \code{stanfit}. In addition, we discuss optimization, which can be 
used to obtain a point estimates via \Stan. 

\subsection[Arguments to the \code{stan} function]{Arguments to the \code{stan} function} 

The primary arguments for sampling (in function \code{stan} and 
\code{sampling}) include data, initial values, and the options of the 
sampler such as \code{chains}, \code{iter}, and \code{warmup}.
In particular, \code{warmup} specifies the number of iterations 
that are used by NUTS sampler for the adaptation phase before sampling begins.
After the warmup, the sampler turns off adaptation and continues until a total of 
\code{iter} iterations have been completed.
There is no theoretical guarantee that the samples are drawn from the posterio distribution 
during warmup, so the warmup samples should only be used for diagnosis and not for
inference.  The summaries for the parameters shown by the \code{print} method
are calculated using only the samples after warmup.

For function \code{stan}, argument \code{init} is used for specifying
the initial values.  There are several options for \code{init} and the 
details can be found in the documentation of the \code{stan} function. The vast majority
of the time, it is adequate to allow \Stan to generate its own initial values randomly.

\Stan uses a random number generator (RNG) that supports parallelism.
The initialization of the RNG is determined by arguments \code{seed}
and \code{chain\_id}.  Even if we are running multiple chains from one call to the \code{stan}, 
function we only need to specify one seed, which is randomly generated by \R if not specified.

\subsection{Data preprocessing and passing}

The data passed to \code{stan} will go through a preprocessing procedure. 
The details of this preprocessing are documented in the help 
for function \code{stan}. Here we stress a few important steps.  
First, \pkg{rstan} allows the user to specify more than what is declared in the data block
and anything beyond that is silently omitted. In general, an element in the input \R list should 
be numeric data and its dimension should match the declaration in the data block of the model.
So for example, \code{factor} type in \R is not supported as data element for \RStan and must
be converted to integer codes. The \Stan modeling language differentiates between integers and doubles
(type \code{int} and \code{real} in Stan modeling language, respectively). The \code{stan} function 
will convert some R data (which is double-precision usually) to \code{integer}s if possible.

In \Stan, we have scalars and other types that are a set of scalars, such as vectors and matrices. 
As \R does not have scalars, \pkg{rstan} treats vectors of length one to be scalars.
However, we might have a model with data block defined as in Figure~\ref{fig0datablock}, 
in which $N$ can be $1$ as a special case.
So if we know that $N$ is always larger than $1$, we can use a vector of length $N$ in \R
as the data input for $y$ (for example, a vector created by ``\code{y <- rnorm(N)}''). 
If we want to prevent \pkg{rstan} from treating the input data for $y$ as a scalar when $N=1$,
we need to explicitly make it an array as the following \R code shows.

<<echo=TRUE>>=
y <- as.array(y)
@


\begin{verbbox}

 data {                
   int<lower=0> N;      
   real y[N];
 } 

\end{verbbox} 

\begin{figure}[hb]
\centering
\frame{
\theverbbox
}
\caption{Data block of an example model in \Stan code}
\label{fig0datablock} 
\end{figure}


As Stan cannot handle missing values in data automatically, all elements of
data cannot contain \code{NA} in \R. An important step in \pkg{rstan}'s data
preprocessing is to check missing values and issue an error if any. To model
missing values using \Stan, you should create binary indicators of whether
a data point is observed or missing and then change the \code{NA} values in \R
to valid numbers before calling \code{stan}.

\subsection[Methods for the \code{stanfit} class]{Methods for the \code{stanfit} class} 

For the fitted object that is an instance of the S4 class \code{stanfit}, we have 
defined methods such as \code{print}, \code{summary}, \code{plot}, \code{pairs}, and 
\code{traceplot}.  We can use these methods to assess the convergence of the Markov chains 
by looking at the trace plots and calculating the split $\hat{R}$.\footnote{Split
$\hat{R}$ is an updated version of $\hat{R}$ statistic proposed in
\cite{GelmanRubin:1992} that is based on splitting each chain
into two halves. See the \Stan manual for more details.} %
The \code{print} method outputs the mean, standard deviation, quantiles of interest, split
$\hat{R}$, and effective sample size for each unknown quantity over all the chains combined.

The \code{plot}\rstanfunidx{plot} method provides an overview of the output, while the
\code{pairs} method shows two-dimensional density plots for each pair of unknown quantities
that are stratified according to the \code{condition} argument. The 
\code{traceplot}\rstanfunidx{traceplot} method plots the traces of all chains for the specified
parameters. If we include the warmup draws by setting \code{inc\_warmup=TRUE} (the 
default), the background color of the warmup area is different from the post-warmup phase.   

Figure~\ref{fig0stanfitplot} presents the plot of the eight schools example. 
In this plot, credible intervals (by default 80\%) for all the parameters
as well as \code{lp\_\_} (the log of posterior density function up to an additive
constant), and the median of each chain are displayed. In addition, under the lines
representing intervals, small colored areas are used to indicate which range the 
value of the split $\hat{R}$ statistic is in. Figure~\ref{fig0stanfittraceplot} shows the
traceplot for the $\tau$ parameter, while Figure~\ref{fig0pairsplot} gives one example
of a \code{pairs} plot, using the median acceptance probability to stratify the draws
into the lower and upper triangles.

\begin{figure}[ht]
\centering
<<echo=false, fig=TRUE, label=stanfit_plot>>=
plot(fit1)
@
\caption{An overview plot for the inference of eight schools example} 
\label{fig0stanfitplot}
\end{figure}

\begin{figure}[ht]
\centering
<<echo=false, fig=TRUE, label=stanfit_tplot, height=4, width=6>>=
traceplot(fit1, pars = "tau")
@
\caption{Trace plots of $\tau$ in the eight schools model} 
\label{fig0stanfittraceplot}
\end{figure}

\begin{figure}[ht]
\centering
<<echo=false, fig=TRUE, label=pairs_plot, height=4, width=6>>=
pairs(fit1, pars = c("mu", "tau", "lp__"), condition = "accept")
@
\caption{Pairs plots of the hyperparameters in the eight schools model}
\label{fig0pairsplot}
\end{figure}

The \code{stanfit} class has a set of methods to work with the samples drawn 
from the posterior distribution. First, the \code{extract}\rstanfunidx{extract} 
method provides different ways to access the samples. If the argument \code{permuted} 
is \code{TRUE}, then the samples after warmup are returned in an permuted order as a 
list, each element of which are the samples for a parameter. Here by ``one parameter'', 
we mean a scalar/vector/array parameter as a whole defined in the parameters block, 
transformed parameters block, or generated quantities block of our Stan program. In the 
eight schools example, $\theta$ is one parameter though it is an array of length $J$. 

If \code{permuted=FALSE}, the result depends on the \code{inc\_warmup} argument.
In either case, the returned object is an array with the first dimension indicating
iterations, the second indicating chains, and the third indicating parameters. If
\code{inc\_warmup=TRUE}, all iterations are included and if \code{inc\_warmup=FALSE},
only the post-warmup iterations are included. The latter is appropriate for inference,
while the former may be useful for diagnosis. In the returned array, each
vector/array parameter is ``flattened'' and are included as the third dimension of
the array. In our eight schools examples, the third dimension is \code{theta[1]}, 
\ldots, \code{theta[8]}.
<<echo=TRUE>>=
s <- extract(fit1, pars = c("theta", "mu"), permuted = TRUE)
names(s)
dim(s$theta)
dim(s$mu)
s2 <- extract(fit1, pars = "theta", permuted = FALSE)
dim(s2)
dimnames(s2)
@

In addition, the \code{as.array}\rstanfunidx{as.array}, \code{as.matrix}\rstanfunidx{as.matrix}, and
\code{as.data.frame}\rstanfunidx{as.data.frame} methods are defined for \code{stanfit} object. These
method return the draws of samples in forms of a 3-dimension array, matrix (\code{rbind}ing the chains), 
or \code{data.frame} (that is coerced from a matrix). There are also 
\code{dimnames}\rstanfunidx{dimnames} and \code{names}\rstanfunidx{names} methods for \code{stanfit}
objects.

A \code{stanfit} object keeps all the information regarding the sampling
procedure, for example, the model in \Stan code, the initial
values for all parameters, the seed for the RNG,
and parameters used for the sampler (for example, the step size for NUTS) 
The following methods
\begin{enumerate}
 \item \code{get\_seed}\rstanfunidx{get\_seed}
 \item \code{get\_inits}\rstanfunidx{get\_inits}
 \item \code{get\_adaptation\_info}\rstanfunidx{get\_adaptation\_info}
 \item \code{get\_sampler\_params}\rstanfunidx{get\_sampler\_params}
\end{enumerate}
for shown in Table~\ref{tab0stanfitfuns} along with other methods defined for the \code{stanfit} class.

Last, a common feature for many methods that are defined for the \code{stanfit} class is that 
the \code{pars} argument can be specified to indicate a subset of the parameters.  This
feature is helpful when there are too many parameters in the model or when we need to reduce memory usage. 
For instance, in the eight schools example, we have parameter $\theta$ defined as
``\code{real theta[J]}''. So we can specify
\code{pars="theta"} or \code{pars="theta[1]"}.
However, specifying part of $\theta$ (i.e., \code{pars="theta[1:2]"}) as in \R
is not allowed --- a workaround for this is to specify \code{pars=c("theta[1]","theta[2]")}. 
The \code{stan} function allows the user to specify \code{pars} so that only part of 
the samples are returned, which might be problematic from the perspective of
diagnosing MCMC convergence since we would apply our diagnostic criterion to a subset
of our parameters. To mitigate this loss of diagnostics information, we can
use the \code{get\_posterior\_mean}\rstanfunidx{get\_posterior\_mean} function,
which returns the posterior mean of all parameters for each chain and all chains combined
(excluding warmup samples). Another alternative is to write the samples to external files 
using the \code{sample\_file} argument of the \code{stan} function and then conduct diagnostics
with the external files.

\subsection{The log posterior function and its gradient} 

Essentially, we define the log of the probability
density function of a posterior distribution up to an unknown additive constant.
In \Stan, we use \code{lp\_\_} to represent the realizations of this log kernel at 
each iteration.   In \pkg{rstan}, \code{lp\_\_} is treated as an unknown
in the summary and the calculation of split $\hat{R}$ and effective sample size.

A nice feature of \pkg{rstan} is that functions for calculating \code{lp\_\_}
and its gradients for a \code{stanfit} object are exposed. They are defined
for a \code{stanfit} object, since we need data to create a model instance. 
These two functions are \code{log\_prob}\rstanfunidx{log\_prob}
and \code{grad\_log\_prob}\rstanfunidx{grad\_log\_prob} respectively. Both take parameters
on the \textit{unconstrained} space, even if the support of a parameter 
is not the whole real line. See \cite{StanManual} for more details
about transformations from the entire real line to some subspace of it. Also the number of 
unconstrained parameters might be less than the number of parameters. For example, when
a parameter is a simplex of length $K$, the number of unconstrained parameters are $K-1$ 
due to the constraint that all elements of a simplex must be nonnegative and sum to one.
The \code{get\_num\_upars}\rstanfunidx{get\_num\_upars} method is provided to get the number 
of unconstrained parameters, while the \code{unconstrained\_pars}\rstanfunidx{unconstrained\_pars} 
and \code{constrained\_pars}\rstanfunidx{constrained\_pars} methods can be used to unconstrain
or constrain parameters respectively. The former takes a list of parameters as input and transforms it 
to an unconstrained vector, and the latter does the opposite. Using these functions, we can implement 
other algorithms such as maximum a posteriori estimation of Bayesian models.

\begin{table}
\begin{tabular}{lp{0.6\linewidth}} 
\toprule 
Name  &    Function    \\ 
\midrule
\code{print}         & print the summary for parameters obtained using all chains  \\
\code{summary}       & summarize the sample from all chains and individual chains for parameters \\
\code{plot}          & plot the inferences (intervals, medians, split $\hat{R}$) for parameters \\
\code{traceplot}     & plot the traces of chains  \\
\code{pairs} & make a matrix of scatter plots for the samples of parameters  \\
\code{extract}       & extract samples of parameters  \\
\code{get\_stancode}     & extract the model code in \Stan modeling language \\
\code{get\_stanmodel}     & extract the \code{stanmodel} object \\ 
\code{get\_seed}      & get the seed used for sampling  \\
\code{get\_inits}     & get the initial values used for sampling  \\
\code{get\_posterior\_mean}     & get the posterior mean for all parameters\\
\code{get\_logposterior}     & get the log posterior (that is, \code{lp\_\_})  \\
\code{get\_sampler\_params}    & get parameters used by the sampler such as \code{treedepth} of NUTS  \\
\code{get\_adaptation\_info}    & get adaptation information of the sampler \\ 
\code{get\_num\_upars}    & get the number of parameters on unconstrained space \\ 
\code{unconstrain\_pars}    & transform parameter to unconstrained space \\ 
\code{constrain\_pars}    & transform parameter from unconstrained space to its defined space \\
\code{log\_prob}    & evaluate the log posterior for parameter on unconstrained space \\
\code{grad\_log\_prob}    & evaluate the gradient of the log posterior for parameter on unconstrained space \\
\code{as.array}        & \multirow{3}{\linewidth}{extract the samples excluding warmup to a three dimension array, matrix, data.frame}  \\
\code{as.matrix}       & \\
\code{as.data.frame}   & \\
\code{dimnames}        & obtain the dimension names of the object in its array representation\\
\code{names}           & obtain the ``flattened'' parameter names\\
\bottomrule 
\end{tabular}
\caption[Methods for the S4 class stanfit]{Methods for the S4 class \code{stanfit}} 
\label{tab0stanfitfuns} 
\end{table}

\subsection[Optimization in Stan]{Optimization in \Stan}
\label{subsecoptimization}

\RStan also provides an interface to \Stan's optimizers, which can be used
to obtain a point estimate by maximizing the (perhaps penalized) likelihood 
function defined by a Stan program. We illustrate the feature using a very simple
example, estimating the mean from samples assumed to be drawn from normal 
distribution with known standard deviation. That is, we assume 

\begin{align*}
y_1,\ldots,y_n\sim \text{normal}(\mu,1).
\end{align*}

By specifying prior of $\mu$ with $p(\mu) \propto 1$, the maximum a posteriori estimator 
for $\mu$ is just the sample mean. The following \R code shows 
how to use \Stan's optimizers in \pkg{rstan}; we first create a \code{stanmodel}
object of \pkg{rstan} and then use its \code{optimizing} method, to which data 
and other arguments can be fed.

<<optimizer, echo=TRUE>>= 
ocode <- "
  data {
    int<lower=1> N;
    real y[N];
  } 
  parameters {
    real mu;
  } 
  model {
    y ~ normal(mu, 1);
  } 
"

sm <- stan_model(model_code = ocode)
y2 <- rnorm(20)
mean(y2)
op <- optimizing(sm, data = list(y = y2, N = length(y2)), hessian = TRUE)
print(op)
@
 

\subsection[Model compiling in rstan]{Model compiling in \pkg{rstan}}
\label{subsecmodelcompiling}

In \RStan, for every model, we use function \code{stanc} to translate the 
model from Stan modeling language code to \Cpp code 
and then compile the \Cpp code to dynamic shared object (DSO),
which is loaded by \R and executed to draw sample. 
The process of compiling \Cpp code to DSO, sometimes, takes a while. 
When the model is the same, we could reuse the DSO from previous run. 
In function \code{stan}, if parameter \code{fit} is specified
with a previous fitted object, the compiled model is reused. 
When reusing a previous fitted model, we can specify different 
data and other parameters for function \code{stan}. 

In addition, if fitted models (objects in our working space of \R)
are saved, for example, by \R function
\code{save} and \code{save.image}, \pkg{rstan} is able to save the 
DSO for models, so that they can be used across \R sessions. 
To (not) save the DSO, specify the \code{save\_dso} argument, which
is \code{TRUE} by default, in the \code{stan} function. 

\Stan runs much faster when the code is compiled at the maximum level of
optimization, which is \code{-O3} on most \Cpp compilers. However, the
default value is \code{-O2} in \R, which is appropriate for most \R
packages but entails a slight slowdown for \Stan. You can change this
default locally by following the instructions at 
\url{http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Customizing-package-compilation}.
However, you should be advised that setting \code{CXXFLAGS = -O3} may
cause adverse side effects for other \R packages.

\subsection{Run multiple chains in parallel}
\label{sec0parallel}

For function \code{stan}, we can specify the number of chains using the \code{chains} argument.
By default, the chains are executed serially (i.e., one at a time) using the parent
\R process. But \pkg{rstan} provides a function called
\code{sflist2stanfit}\rstanfunidx{sflist2stanfit} that
consolidates a list of multiple \code{stanfit} objects (sampled from one model with
the same number of warmup and iteration) into one \code{stanfit} object. Thus, we can run 
multiple chains in parallel using any approach provided by other \R packages on one computer 
or a networked cluster. There is a CRAN-incompatible function at
\url{http://mc-stan.org/rstan/stan.R}
that can be \code{source}d to supersede the \code{stan} function in \pkg{rstan}. This function
should work on a typical multicore laptop but could be adapted to work on more exotic computer
clusters. This function also saves compiled \code{stanfit} objects to the working directory
or the temporary directory and checks whether an identical compiled model is available on the disk 
before compiling a new one.

However one does parallel sampling, it is important to specify the same seed for all the chains
and equally important to use a different chain ID (argument \code{chain\_id}). This ensures
that the random numbers generated in \Stan for all chains are essentially independent. 

\section[Working with CmdStan]{Working with \CmdStan} 
\label{sec0workwstan}

RStan provides some functions to help use \Stan from the command line, \CmdStan.
First, when \Stan reads data or initial
values, it supports a subset of the syntax of \R dump data formats.  
So if we use \code{dump} function in \R to prepare data, \Stan
might not be able to read the data. The \code{stan\_rdump} function in \pkg{rstan} 
dumps the data from \R to a format that is supported by \Stan with symantics that are very 
similar to the \code{dump} function in \R.

Second, the \code{read\_stan\_csv}\rstanfunidx{read\_stan\_csv} function 
in \pkg{rstan} creates a \code{stanfit} object from reading the comma separated
files (CSV) generated by \CmdStan. As a result, we can use any methods
defined for the \code{stanfit} class to diagnose and analyze the samples.

\section{Summary} 
\label{sec0summary}

In this vignette, we have described the main functionality of RStan
from a user's perspective. The help pages with the \pkg{rstan} package provide more details
for all exposed \pkg{rstan} functions. The \Stan manual (\citealt{StanManual}) provides 
many details and includes a variety of model examples, many of which are included in the
suggested \pkg{rstanDemo} package that also provides the \code{stan\_demo} function to choose 
and execute them.

\nocite{*} 
\bibliography{rstan} 

\printindex

\end{document} 

